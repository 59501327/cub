/******************************************************************************
 * Copyright (c) 2011, Duane Merrill.  All rights reserved.
 * Copyright (c) 2011-2013, NVIDIA CORPORATION.  All rights reserved.
 * 
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *     * Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *     * Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *     * Neither the name of the NVIDIA CORPORATION nor the
 *       names of its contributors may be used to endorse or promote products
 *       derived from this software without specific prior written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 ******************************************************************************/
 
 

/**
 * \mainpage
 *
 * \tableofcontents
 *
 * \htmlonly
 * <a href="http://research.nvidia.com"><img src="nvresearch.png" style="position:relative; bottom:-10px; border:0px;"/></a>
 * &nbsp;&nbsp;
 * <a href="http://research.nvidia.com"><em>NVIDIA Research</em></a>
 * <br>
 * <a href="https://github.com/NVlabs/cub"><img src="github-icon-747d8b799a48162434b2c0595ba1317e.png" style="position:relative; bottom:-10px; border:0px;"/></a>
 * &nbsp;&nbsp;
 * <a href="https://github.com/NVlabs/cub"><em>Browse or fork CUB at GitHub</em></a>
 * <br>
 * <a href="http://groups.google.com/group/cub-users"><img src="groups-icon.png" style="position:relative; bottom:-10px; border:0px;"/></a>
 * &nbsp;&nbsp;
 * <a href="http://groups.google.com/group/cub-users"><em>Join the cub-users discussion forum</em></a>
 * <br>
 * <a href="download_cub.html"><img src="download-icon.png" style="position:relative; bottom:-10px; border:0px;"/></a>
 * &nbsp;&nbsp;
 * <a href="download_cub.html"><em>Download the current CUB release (v1.0.1)</em></a>
 * \endhtmlonly
 *
 * \section sec0 (1) What is CUB?
 *
 * \par
 * CUB provides state-of-the-art reusable software components for every layer 
 * of the CUDA programming model:
 * - [<b><em>Device-wide primitives</em></b>] (group___device_module.html) 
 *   - Histogram, reduction, prefix scan, sort, etc.  
 *   - Compatible with CUDA dynamic parallelism
 * - [<b><em>Block-wide "collective" primitives</em></b>] (group___block_module.html)
 *   - I/O, histogram, reduction, prefix scan, sort, etc.  
 *   - Compatible with arbitrary thread block sizes and types 
 * - [<b><em>Warp-wide "collective" primitives</em></b>] (group___warp_module.html)
 *   - Warp-wide prefix scan, reduction, etc.
 *   - Safe and architecture-specific
 * - [<b><em>Thread and resource utilities</em></b>](group___thread_module.html)
 *   - PTX intrinsics, device reflection, texture-caching iterators, caching memory allocators, etc. 
 *
 * \subsection sec0sec1 1.1 Collective Primitives 
 * \par
 * As a SIMT programming model, CUDA engenders both (1) <em><b>scalar</b></em> and 
 * (2) <em><b>collective</b></em> software interfaces. Traditional software 
 * interfaces are <em>scalar</em>: a single thread invokes a library routine to perform some 
 * operation (which may include spawning parallel subtasks).  Alternatively, a <em>collective</em> 
 * interface is entered simultaneously by a group of parallel threads to perform 
 * some cooperative operation.  
 *
 * \par
 * \image html cub_overview.png
 * <div class="centercaption">Orientation of <em>collective</em> primitives within the CUDA software stack</div>
 * 
 * \par 
 * Collective primitives are essential for constructing performance-portabable 
 * kernels for use in higher level software abstractions, libraries, 
 * domain-specific languages, etc.  
 * 
 * \par
 * CUB's collective primitives are not bound 
 * to any particular width of parallelism or to any particular data type.  
 * This allows them to be flexible and tunable to fit the needs of the enclosing 
 * kernel computation. Thus CUB is [<em>CUDA Unbound</em>](index.html).
 *
 * \subsection sec0sec2 1.2 Design Motivation 
 * \par 
 * CUB is inspired by the following goals:
 * - <em><b>Absolute performance</b></em>.  CUB primitives are specialized and tuned to 
 *   best match the features and capabilities of every CUDA architecture.
 * - <em><b>Enhanced programmer productivity</b></em>.  CUB primitives allow developers to quickly 
 *   string together sequences of complex parallel operations in both CUDA kernel code and CUDA host code.       
 * - <em><b>Reduced maintenance burden</b></em>.  CUB provides a SIMT software abstraction layer 
 *   over the diversity of CUDA hardware.  With CUB, applications can enjoy 
 *   performance-portability without intensive and costly rewriting or porting efforts.  
 * 
 * \section sec2 (2) An Example (block-sorting)
 *
 * \par
 * The following code snippet presents a simple CUDA kernel in which each 128-thread block
 * sorts its own segment of 2048 integer keys:
 *
 * \par
 * \code
 * #include <cub/cub.cuh>
 *
 * // Block-sorting CUDA kernel
 * __global__ void BlockSortKernel(int *d_in, int *d_out)
 * {
 *      using namespace cub;
 *
 *      // Specialize BlockRadixSort, BlockLoad, and BlockStore for 128 threads 
 *      // owning 16 integer items each
 *      typedef BlockRadixSort<int, 128, 16>                     BlockRadixSort;
 *      typedef BlockLoad<int*, 128, 16, BLOCK_LOAD_TRANSPOSE>   BlockLoad;
 *      typedef BlockStore<int*, 128, 16, BLOCK_STORE_TRANSPOSE> BlockStore;
 *
 *      // Allocate shared memory
 *      __shared__ union {
 *          typename BlockRadixSort::TempStorage  sort;
 *          typename BlockLoad::TempStorage       load; 
 *          typename BlockStore::TempStorage      store; 
 *      } temp_storage; 
 *
 *      int block_offset = (blockIdx.x * 128 * 16);	  // Offset for this block's segment
 * 
 *      // Obtain a segment of consecutive keys that are blocked across threads
 *      T thread_keys[16];
 *      BlockLoad(temp_storage.load).Load(d_in + block_offset, thread_keys);
 *      __syncthreads();
 *
 *      // Collectively sort the keys
 *      BlockRadixSort(temp_storage.sort).Sort(thread_keys);
 *      __syncthreads();
 *
 *      // Store the sorted segment 
 *      BlockStore(temp_storage.store).Store(d_out + block_offset, thread_keys);
 * }
 * \endcode
 *
 * \par
 * Each thread block uses cub::BlockRadixSort to collectively sort 
 * its own input segment.  The class is specialized by the 
 * data type being sorted, by the number of threads per block, by the number of 
 * keys per thread, and implicitly by the target compilation architecture.  
 * 
 * \par
 * The cub::BlockLoad and cub::BlockStore classes are similarly specialized.    
 * To provide coalesced accesses to device memory, these primitives are specialized 
 * to access memory using a striped access pattern (where consecutive threads 
 * simultaneously access consecutive items) and then <em>transpose</em> the keys into 
 * a [<em>blocked arrangements</em>](index.html#sec3sec3) of elements across threads. 
 *
 * \par
 * Once specialized, these classes expose opaque \p TempStorage member types.  
 * The thread block uses these storage types to statically allocate the union of 
 * shared memory needed by the thread block.  (Alternatively these storage types 
 * could be aliased to global memory allocations).
 *
 * \section sec3 (3) Recent News
 *
 * \par
 * <table>
 * <tr> <td>08/08/2013</td> <td style="white-space: nowrap">[CUB v1.0.1 (primary release)](https://github.com/NVlabs/cub/archive/1.0.1.zip)</td> 	
 * <td>
 * - New device-wide primitives for prefix scan and radix sort (significantly faster than Thrust, B40C, MGPU, etc.) 
 * - New collective interface idiom (specialize::construct::invoke).
 * - Significantly improved documentation (with example code snippets) 
 * - Improved support for Kepler (SM35), CUDA 5.5, and Dynamic Parallelism.  
 * - See the [change-log](https://github.com/NVlabs/cub/blob/master/CHANGE_LOG.TXT) for further details.</td> </tr>
 * 
 * <tr> <td>05/07/2013</td> <td style="white-space: nowrap">[CUB v0.9.4 (update release)](https://github.com/NVlabs/cub/archive/0.9.4.zip)</td> 	
 * <td>
 * - Compilation fixes for several primitives on older architectures.  
 * - Introduced several new device-wide and block-wide primitives, including 256-bin histogram.  
 * - Misc. cosmetic and bug fixes.  
 * - See the [change-log](https://github.com/NVlabs/cub/blob/master/CHANGE_LOG.TXT) for further details.</td> </tr>
 * 
 * <tr> <td>04/04/2013</td> <td style="white-space: nowrap">[CUB v0.9.2 (update release)](https://github.com/NVlabs/cub/archive/0.9.2.zip)</td> 	
 * <td>
 * - Minor cosmetic, feature, and compilation updates.  
 * - See the [change-log](https://github.com/NVlabs/cub/blob/master/CHANGE_LOG.TXT) for further details.</td> </tr>
 * 
 * <tr> <td>03/07/2013</td> <td style="white-space: nowrap">[CUB v0.9 (preview release)](https://github.com/NVlabs/cub/archive/0.9.zip)</td> 		
 * <td>
 * - CUB is the first durable, high-performance library of cooperative threadblock, warp, and 
 *   thread primitives for CUDA kernel programming.</td> </tr>
 * </table> 
 *
 *
 * \section sec4 (4) Why do you need CUB?
 *
 * \par
 * CUDA kernel software is where the complexity of parallelism is expressed.
 * Programmers must reason about deadlock, livelock, synchronization, race conditions,
 * shared memory layout, plurality of state, granularity, throughput, latency,
 * memory bottlenecks, etc. Constructing and fine-tuning kernel code is perhaps the
 * most challenging, time-consuming aspect of CUDA programming.
 *
 * \par
 * However, with the exception of CUB, there are few (if any) software libraries of
 * reusable kernel primitives. In the CUDA ecosystem, CUB is unique in this regard.
 * As a [SIMT](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-implementation)
 * library and software abstraction layer, CUB provides:
 * -# <b>Simplicity of composition.</b>  Parallel CUB primitives can be simply sequenced
 *    together in kernel code.  (This convenience is analogous to programming with
 *    [<b><em>Thrust</em></b>](http://thrust.github.com/) primitives in the host program.)
 * -# <b>High performance.</b> CUB simplifies high performance kernel development by
 *    taking care to implement and make available the fastest available algorithms,
 *    strategies, and techniques.
 * -# <b>Performance portability.</b> CUB primitives are specialized to match
 *    the target hardware.  Furthermore, the CUB library continually evolves to accommodate new
 *    algorithmic developments, hardware instructions, etc.
 * -# <b>Simplicity of performance tuning.</b>  CUB primitives provide parallel abstractions
 *    whose performance behavior can be statically tuned.  For example, most CUB primitives
 *    support alternative algorithmic strategies and variable grain sizes (threads per block,
 *    items per thread, etc.).
 * -# <b>Robustness and durability.</b> CUB primitives are designed to function properly for
 *    arbitrary data types and widths of parallelism (not just for the built-in C++ types
 *    or for powers-of-two threads per block).
 *
 * \section sec5 (5) Where is CUB positioned in the CUDA ecosystem?
 *
 * \par
 * The CUDA ecosystem engenders four different layers of software abstraction:
 *
 * <table border="0px" cellpadding="0px" cellspacing="0px"><tr>
 * <td width="50%">
 * \par
 * <b>Runtime-agnostic</b>.  A single thread calls through a library interface to 
 * perform some data-parallel function.  The use of any particular parallel 
 * or sequential computing backend (e.g., CUDA, TBB, OpenMP, etc.) is opaque to the caller.  
 * Although these libraries are not CUDA-specific, primitives such as those 
 * provided by CUB can be used to implement them.  Examples include:
 * - [<b><em>Thrust</em></b>](http://thrust.github.com/)
 * - [<b><em>Hemi</em></b>](https://github.com/harrism/hemi)
 * - [<b><em>ArrayFire</em></b>](http://www.accelereyes.com/products/arrayfire)
 * </td>
 * <td width="50%">
 * \htmlonly
 * <a href="generic_abstraction.png"><img src="generic_abstraction.png" width="100%" border="0px"/></a>
 * \endhtmlonly
 * </td>
 * </tr><tr>
 * <td width="50%">
 * \par
 * <b>CUDA kernel</b>.  A single CPU thread invokes a CUDA kernel to perform
 * some data-parallel function.  The incorporation of entire kernels (and their
 * corresponding invocation stubs) into libraries is the most common form of code reuse for
 * CUDA.  Libraries of CUDA kernels include the following:
 * - [<b><em>cuBLAS</em></b>](https://developer.nvidia.com/cublas)
 * - [<b><em>cuFF</em>T</b>](https://developer.nvidia.com/cufft)
 * - [<b><em>cuSPARSE</em></b>](https://developer.nvidia.com/cusparse)
 * - [<b><em>CUB</em></b>](index.html)
 * </td>
 * <td width="50%">
 * \htmlonly
 * <a href="kernel_abstraction.png"><img src="kernel_abstraction.png" width="100%" border="0px"/></a>
 * \endhtmlonly
 * </td>
 * </tr><tr>
 * <td>
 * \par
 * <b>Thread blocks (SIMT)</b>.  Each kernel invocation comprises some number of parallel
 * threads.  Threads are grouped into blocks, and the entire block of threads invokes some cooperative
 * function  in which they communicate and synchronize with each other.  There has historically been very
 * little reuse of cooperative SIMT software within CUDA kernel.  Libraries of thread-block primitives
 * include the following:
 * - [<b><em>CUB</em></b>](index.html)
 * </td>
 * <td>
 * \htmlonly
 * <a href="simt_abstraction.png"><img src="simt_abstraction.png" width="100%" border="0px"/></a>
 * \endhtmlonly
 * </td>
 * </tr><tr>
 * <td>
 * \par
 * <b>CUDA thread</b>.  A single CUDA thread invokes some sequential function.
 * This is the finest-grained level of CUDA software abstraction and requires
 * no consideration for the scheduling or synchronization of parallel threads.  CUDA libraries of
 * purely data-parallel functions include the following:
 * - [<b><em> CUDA Math</em></b>](http://docs.nvidia.com/cuda/cuda-math-api/index.html),
 *   [<b><em>Texture</em></b>](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#texture-functions), and
 *   [<b><em>Atomic</em></b>](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions) APIs
 * - [<b><em>cuRAND</em></b>](https://developer.nvidia.com/curand)'s device-code interface
 * - [<b><em>CUB</em></b>](index.html)
 * </td>
 * <td>
 * \htmlonly
 * <a href="devfun_abstraction.png"><img src="devfun_abstraction.png" width="100%" border="0px"/></a>
 * \endhtmlonly
 * </td>
 * </tr></table>
 *
 *
 * \section sec6 (6) How does CUB work?
 *
 * \par
 * CUB leverages the following programming idioms:
 * -# [<b>C++ templates</b>](index.html#sec3sec1)
 * -# [<b>Reflective type structure</b>](index.html#sec3sec2)
 * -# [<b>Flexible data mapping</b>](index.html#sec3sec3)
 *
 * \subsection sec3sec1 6.1 &nbsp;&nbsp; C++ templates
 *
 * \par
 * As a SIMT library, CUB must be flexible enough to accommodate a wide spectrum
 * of <em>parallel execution contexts</em>,
 * i.e., specific:
 *    - Data types
 *    - Widths of parallelism (threads per block)
 *    - Grain sizes (data items per thread)
 *    - Underlying architectures (special instructions, warp size, rules for bank conflicts, etc.)
 *    - Tuning requirements (e.g., latency vs. throughput)
 *
 * \par
 * To provide this flexibility, CUB is implemented as a C++ template library.
 * C++ templates are a way to write generic algorithms and data structures.
 * There is no need to build CUB separately.  You simply <tt>\#include</tt> the
 * <tt>cub.cuh</tt> header file into your <tt>.cu</tt> CUDA C++ sources
 * and compile with NVIDIA's <tt>nvcc</tt> compiler.
 *
 * \subsection sec3sec2 6.2 &nbsp;&nbsp; Reflective type structure
 *
 * \par
 * Cooperation within a thread block requires shared memory for communicating between threads.
 * However, the specific size and layout of the memory needed by a given
 * primitive will be specific to the details of its parallel execution context (e.g., how
 * many threads are calling into it, how many items are processed per thread, etc.).  Furthermore,
 * this shared memory must be allocated outside of the component itself if it is to be
 * reused elsewhere by the thread block.
 *
 * \par
 * \code
 * // Parameterize a BlockScan type for use with 128 threads
 * // and 4 items per thread
 * typedef cub::BlockScan<unsigned int, 128, 4> BlockScan;
 *
 * // Declare shared memory for BlockScan
 * __shared__ typename BlockScan::TempStorage temp_storage;
 *
 * // A segment of consecutive input items per thread
 * int data[4];
 *
 * // Obtain data in blocked order
 * ...
 *
 * // Perform an exclusive prefix sum across the tile of data
 * BlockScan::ExclusiveSum(temp_storage, data, data);
 *
 * \endcode
 *
 * \par
 * To address this issue, we encapsulate cooperative procedures within
 * <em>reflective type structure</em> (C++ classes).  As illustrated in the
 * cub::BlockScan example above, these primitives are C++ classes with
 * interfaces that expose both:
 * - Procedural entrypoints for a block of threads to invoke
 * - An opaque shared memory type needed for the operation of those methods
 *
 * \subsection sec3sec3 6.3 &nbsp;&nbsp; Flexible mapping of data onto threads
 *
 * \par
 * We often design kernels such that each thread block is assigned a "tile" of data
 * items for processing.
 *
 * \par
 * \image html tile.png
 * <div class="centercaption">Tile of eight ordered data items</div>
 *
 * \par
 * When the tile size equals the thread block size, the
 * mapping of data onto threads is straightforward (one datum per thread).
 * However, there are often performance advantages for processing more
 * than one datum per thread.  For these scenarios, CUB primitives
 * will specify which of the following partitioning alternatives they 
 * accommodate:
 *
 * <table border="0px" cellpadding="0px" cellspacing="0px"><tr>
 * <td>
 * \par
 * - <b><em>Blocked arrangement</em></b>.  The aggregate tile of items is partitioned
 *   evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub>
 *   owning the <em>i</em><sup>th</sup> segment of consecutive elements.
 *   Blocked arrangements are often desirable for algorithmic benefits (where
 *   long sequences of items can be processed sequentially within each thread).
 * </td>
 * <td>
 * \par
 * \image html blocked.png
 * <div class="centercaption"><em>Blocked</em> arrangement across four threads <br>(emphasis on items owned by <em>thread</em><sub>0</sub>)</div>
 * </td>
 * </tr><tr>
 * <td>
 * \par
 * - <b><em>Striped arrangement</em></b>.  The aggregate tile of items is partitioned across
 *   threads in "striped" fashion, i.e., the \p ITEMS_PER_THREAD items owned by
 *   each thread have logical stride \p BLOCK_THREADS between them. Striped arrangements
 *   are often desirable for data movement through global memory (where
 *   [read/write coalescing](http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/#coalesced-access-global-memory)</a>
 *   is an important performance consideration).
 * </td>
 * <td>
 * \par
 * \image html striped.png
 * <div class="centercaption"><em>Striped</em> arrangement across four threads <br>(emphasis on items owned by <em>thread</em><sub>0</sub>)</div>
 * </td>
 * </tr></table>
 *
 * \par
 * The benefits of processing multiple items per thread (a.k.a., <em>register blocking</em>, <em>granularity coarsening</em>, etc.) include:
 * - Algorithmic efficiency.  Sequential work over multiple items in
 *   thread-private registers is cheaper than synchronized, cooperative
 *   work through shared memory spaces.
 * - Data occupancy.  The number of items that can be resident on-chip in
 *   thread-private register storage is often greater than the number of
 *   schedulable threads.
 * - Instruction-level parallelism.  Multiple items per thread also
 *   facilitates greater ILP for improved throughput and utilization.
 *
 * \par
 * Finally, cub::BlockExchange provides operations for converting between blocked
 * and striped arrangements.
 *
 * \section sec7 (7) Contributors
 *
 * \par
 * CUB is developed as an open-source project by [NVIDIA Research](http://research.nvidia.com).
 * The primary contributor is [Duane Merrill](http://github.com/dumerrill).
 *
 * \section sec8 (8) Open Source License
 *
 * \par
 * CUB is available under the "New BSD" open-source license:
 *
 * \par
 * \code
 * Copyright (c) 2011, Duane Merrill.  All rights reserved.
 * Copyright (c) 2011-2013, NVIDIA CORPORATION.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *     * Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *     * Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *     * Neither the name of the NVIDIA CORPORATION nor the
 *       names of its contributors may be used to endorse or promote products
 *       derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 * \endcode
 *
 */


/**
 * \defgroup DeviceModule Device-wide
 */

/**
 * \defgroup BlockModule Block-wide
 */

/**
 * \defgroup WarpModule Warp-wide
 */

/**
 * \defgroup ThreadModule Thread
 */

/**
 * \defgroup IoModule Kernel I/O
 */

/**
 * \defgroup GridModule Grid utilities
 */

/**
 * \defgroup UtilModule Generic CUB utilities
 */
